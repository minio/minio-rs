// MinIO Rust Library for Amazon S3 Compatible Cloud Storage
// Copyright 2023 MinIO, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

use super::ObjectContent;
use crate::s3::builders::{ContentStream, Size};
use crate::s3::client::MinioClient;
use crate::s3::error::{Error, IoError, ValidationErr};
use crate::s3::header_constants::*;
use crate::s3::multimap_ext::{Multimap, MultimapExt};
use crate::s3::response::a_response_traits::HasEtagFromHeaders;
use crate::s3::response::{
    AbortMultipartUploadResponse, CompleteMultipartUploadResponse, CreateMultipartUploadResponse,
    PutObjectContentResponse, PutObjectResponse, UploadPartResponse,
};
use crate::s3::segmented_bytes::SegmentedBytes;
use crate::s3::sse::Sse;
use crate::s3::types::{PartInfo, Retention, S3Api, S3Request, ToS3Request};
use crate::s3::utils::{check_bucket_name, md5sum_hash, to_iso8601utc, url_encode};
use crate::s3::utils::{check_object_name, check_sse, insert};
use bytes::{Bytes, BytesMut};
use http::Method;
use std::{collections::HashMap, sync::Arc};
use typed_builder::TypedBuilder;
// region: multipart-upload

/// Argument builder for the [`CreateMultipartUpload`](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateMultipartUpload.html) S3 API operation.
///
/// This struct constructs the parameters required for the [`Client::create_multipart_upload`](crate::s3::client::MinioClient::create_multipart_upload) method.
#[derive(Clone, Debug, TypedBuilder)]
pub struct CreateMultipartUpload {
    #[builder(!default)] // force required
    client: MinioClient,
    #[builder(default, setter(into))]
    extra_headers: Option<Multimap>,
    #[builder(default, setter(into))]
    extra_query_params: Option<Multimap>,
    #[builder(default, setter(into))]
    region: Option<String>,
    #[builder(setter(into))] // force required + accept Into<String>
    bucket: String,
    #[builder(setter(into))] // force required + accept Into<String>
    object: String,

    #[builder(default, setter(into))]
    user_metadata: Option<Multimap>,
    #[builder(default, setter(into))]
    sse: Option<Arc<dyn Sse>>,
    #[builder(default, setter(into))]
    tags: Option<HashMap<String, String>>,
    #[builder(default, setter(into))]
    retention: Option<Retention>,
    #[builder(default = false)]
    legal_hold: bool,
    #[builder(default, setter(into))]
    content_type: Option<String>,
}

/// Builder type for [`CreateMultipartUpload`] that is returned by [`MinioClient::create_multipart_upload`](crate::s3::client::MinioClient::create_multipart_upload).
///
/// This type alias simplifies the complex generic signature generated by the `typed_builder` crate.
pub type CreateMultipartUploadBldr = CreateMultipartUploadBuilder<(
    (MinioClient,),
    (),
    (),
    (),
    (String,),
    (String,),
    (),
    (),
    (),
    (),
    (),
    (),
)>;

impl S3Api for CreateMultipartUpload {
    type S3Response = CreateMultipartUploadResponse;
}

impl ToS3Request for CreateMultipartUpload {
    fn to_s3request(self) -> Result<S3Request, ValidationErr> {
        check_bucket_name(&self.bucket, true)?;
        check_object_name(&self.object)?;

        let headers: Multimap = into_headers_put_object(
            self.extra_headers,
            self.user_metadata,
            self.sse,
            self.tags,
            self.retention,
            self.legal_hold,
            self.content_type,
        )?;

        Ok(S3Request::builder()
            .client(self.client)
            .method(Method::POST)
            .region(self.region)
            .bucket(self.bucket)
            .object(self.object)
            .query_params(insert(self.extra_query_params, "uploads"))
            .headers(headers)
            .build())
    }
}

// endregion: multipart-upload

// region: abort-multipart-upload

/// Argument for
/// [abort_multipart_upload()](crate::s3::client::MinioClient::abort_multipart_upload)
/// API
#[derive(Clone, Debug, TypedBuilder)]
pub struct AbortMultipartUpload {
    #[builder(!default)] // force required
    client: MinioClient,
    #[builder(default, setter(into))]
    extra_headers: Option<Multimap>,
    #[builder(default, setter(into))]
    extra_query_params: Option<Multimap>,
    #[builder(default, setter(into))]
    region: Option<String>,
    #[builder(setter(into))] // force required + accept Into<String>
    bucket: String,
    #[builder(setter(into))] // force required + accept Into<String>
    object: String,
    #[builder(setter(into))] // force required + accept Into<String>
    upload_id: String,
}

/// Builder type for [`AbortMultipartUpload`] that is returned by [`MinioClient::abort_multipart_upload`](crate::s3::client::MinioClient::abort_multipart_upload).
///
/// This type alias simplifies the complex generic signature generated by the `typed_builder` crate.
pub type AbortMultipartUploadBldr =
    AbortMultipartUploadBuilder<((MinioClient,), (), (), (), (String,), (String,), (String,))>;

impl S3Api for AbortMultipartUpload {
    type S3Response = AbortMultipartUploadResponse;
}

impl ToS3Request for AbortMultipartUpload {
    fn to_s3request(self) -> Result<S3Request, ValidationErr> {
        check_bucket_name(&self.bucket, true)?;
        check_object_name(&self.object)?;

        let headers: Multimap = self.extra_headers.unwrap_or_default();
        let mut query_params: Multimap = self.extra_query_params.unwrap_or_default();
        query_params.add("uploadId", url_encode(&self.upload_id).to_string());

        Ok(S3Request::builder()
            .client(self.client)
            .method(Method::DELETE)
            .region(self.region)
            .bucket(self.bucket)
            .object(self.object)
            .query_params(query_params)
            .headers(headers)
            .build())
    }
}

// endregion: abort-multipart-upload

// region: complete-multipart-upload

/// Argument for
/// [complete_multipart_upload()](crate::s3::client::MinioClient::complete_multipart_upload)
/// API
#[derive(Clone, Debug, TypedBuilder)]
pub struct CompleteMultipartUpload {
    #[builder(!default)] // force required
    client: MinioClient,
    #[builder(default, setter(into))]
    extra_headers: Option<Multimap>,
    #[builder(default, setter(into))]
    extra_query_params: Option<Multimap>,
    #[builder(default, setter(into))]
    region: Option<String>,
    #[builder(setter(into))] // force required + accept Into<String>
    bucket: String,
    #[builder(setter(into))] // force required + accept Into<String>
    object: String,
    #[builder(setter(into))] // force required + accept Into<String>
    upload_id: String,
    #[builder(!default)] // force required
    parts: Vec<PartInfo>,
}

/// Builder type for [`CompleteMultipartUpload`] that is returned by [`MinioClient::complete_multipart_upload`](crate::s3::client::MinioClient::complete_multipart_upload).
///
/// This type alias simplifies the complex generic signature generated by the `typed_builder` crate.
pub type CompleteMultipartUploadBldr = CompleteMultipartUploadBuilder<(
    (MinioClient,),
    (),
    (),
    (),
    (String,),
    (String,),
    (String,),
    (Vec<PartInfo>,),
)>;

impl S3Api for CompleteMultipartUpload {
    type S3Response = CompleteMultipartUploadResponse;
}

impl ToS3Request for CompleteMultipartUpload {
    fn to_s3request(self) -> Result<S3Request, ValidationErr> {
        {
            check_bucket_name(&self.bucket, true)?;
            check_object_name(&self.object)?;
            if self.upload_id.is_empty() {
                return Err(ValidationErr::InvalidUploadId(
                    "upload ID cannot be empty".into(),
                ));
            }
            if self.parts.is_empty() {
                return Err(ValidationErr::EmptyParts("parts cannot be empty".into()));
            }
        }

        // Set the capacity of the byte-buffer based on the part count - attempting
        // to avoid extra allocations when building the XML payload.
        let bytes: Bytes = {
            let mut data = BytesMut::with_capacity(100 * self.parts.len() + 100);
            data.extend_from_slice(b"<CompleteMultipartUpload>");
            for part in self.parts.iter() {
                data.extend_from_slice(b"<Part><PartNumber>");
                data.extend_from_slice(part.number.to_string().as_bytes());
                data.extend_from_slice(b"</PartNumber><ETag>");
                data.extend_from_slice(part.etag.as_bytes());
                data.extend_from_slice(b"</ETag></Part>");
            }
            data.extend_from_slice(b"</CompleteMultipartUpload>");
            data.freeze()
        };

        let mut headers: Multimap = self.extra_headers.unwrap_or_default();
        {
            headers.add(CONTENT_TYPE, "application/xml");
            headers.add(CONTENT_MD5, md5sum_hash(bytes.as_ref()));
        }
        let mut query_params: Multimap = self.extra_query_params.unwrap_or_default();
        query_params.add("uploadId", self.upload_id);
        let body = Arc::new(SegmentedBytes::from(bytes));

        Ok(S3Request::builder()
            .client(self.client)
            .method(Method::POST)
            .region(self.region)
            .bucket(self.bucket)
            .object(self.object)
            .query_params(query_params)
            .headers(headers)
            .body(body)
            .build())
    }
}
// endregion: complete-multipart-upload

// region: upload-part

/// Argument for [upload_part()](crate::s3::client::MinioClient::upload_part) S3 API
#[derive(Debug, Clone, TypedBuilder)]
pub struct UploadPart {
    #[builder(!default)] // force required
    client: MinioClient,
    #[builder(default, setter(into))]
    extra_headers: Option<Multimap>,
    #[builder(default, setter(into))]
    extra_query_params: Option<Multimap>,
    #[builder(setter(into))] // force required + accept Into<String>
    bucket: String,
    #[builder(setter(into))] // force required + accept Into<String>
    object: String,
    #[builder(default, setter(into))]
    region: Option<String>,
    #[builder(default, setter(into))]
    sse: Option<Arc<dyn Sse>>,
    #[builder(default, setter(into))]
    tags: Option<HashMap<String, String>>,
    #[builder(default, setter(into))]
    retention: Option<Retention>,
    #[builder(default = false)]
    legal_hold: bool,
    #[builder(!default)] // force required
    data: Arc<SegmentedBytes>,
    #[builder(default, setter(into))]
    content_type: Option<String>,

    // This is used only when this struct is used for PutObject.
    #[builder(default, setter(into))]
    user_metadata: Option<Multimap>,

    // These are only used for multipart UploadPart but not for PutObject, so
    // they are optional.
    #[builder(default, setter(into))] // force required
    upload_id: Option<String>,
    #[builder(default, setter(into))] // force required
    part_number: Option<u16>,
}

/// Builder type for [`UploadPart`] that is returned by [`MinioClient::upload_part`](crate::s3::client::MinioClient::upload_part).
///
/// This type alias simplifies the complex generic signature generated by the `typed_builder` crate.
pub type UploadPartBldr = UploadPartBuilder<(
    (MinioClient,),
    (),
    (),
    (String,),
    (String,),
    (),
    (),
    (),
    (),
    (),
    (Arc<SegmentedBytes>,),
    (),
    (),
    (Option<String>,),
    (Option<u16>,),
)>;

impl S3Api for UploadPart {
    type S3Response = UploadPartResponse;
}

impl ToS3Request for UploadPart {
    fn to_s3request(self) -> Result<S3Request, ValidationErr> {
        {
            check_bucket_name(&self.bucket, true)?;
            check_object_name(&self.object)?;

            if let Some(upload_id) = &self.upload_id
                && upload_id.is_empty()
            {
                return Err(ValidationErr::InvalidUploadId(
                    "upload ID cannot be empty".into(),
                ));
            }
            if let Some(part_number) = self.part_number
                && !(1..=MAX_MULTIPART_COUNT).contains(&part_number)
            {
                return Err(ValidationErr::InvalidPartNumber(format!(
                    "part number must be between 1 and {MAX_MULTIPART_COUNT}"
                )));
            }
        }

        let headers: Multimap = into_headers_put_object(
            self.extra_headers,
            self.user_metadata,
            self.sse,
            self.tags,
            self.retention,
            self.legal_hold,
            self.content_type,
        )?;

        let mut query_params: Multimap = self.extra_query_params.unwrap_or_default();

        if let Some(upload_id) = self.upload_id {
            query_params.add("uploadId", upload_id);
        }
        if let Some(part_number) = self.part_number {
            query_params.add("partNumber", part_number.to_string());
        }

        Ok(S3Request::builder()
            .client(self.client)
            .method(Method::PUT)
            .region(self.region)
            .bucket(self.bucket)
            .query_params(query_params)
            .object(self.object)
            .headers(headers)
            .body(self.data)
            .build())
    }
}

// endregion: upload-part

// region: put-object

/// Argument builder for the [`PutObject`](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html) S3 API operation.
///
/// This struct constructs the parameters required for the [`Client::put_object`](crate::s3::client::Client::put_object) method.
#[derive(Debug, Clone, TypedBuilder)]
pub struct PutObject {
    pub(crate) inner: UploadPart,
}

/// Builder type for [`PutObject`] that is returned by [`MinioClient::put_object`](crate::s3::client::MinioClient::put_object).
///
/// This type alias simplifies the complex generic signature generated by the `typed_builder` crate.
pub type PutObjectBldr = PutObjectBuilder<((UploadPart,),)>;

impl S3Api for PutObject {
    type S3Response = PutObjectResponse;
}

impl ToS3Request for PutObject {
    fn to_s3request(self) -> Result<S3Request, ValidationErr> {
        self.inner.to_s3request()
    }
}

// endregion: put-object

// region: put-object-content

/// Argument builder for the [`PutObject`](https://docs.aws.amazon.com/AmazonS3/latest/API/API_PutObject.html) S3 API operation with streaming content.
///
/// This struct constructs the parameters required for the [`Client::put_object_content`](crate::s3::client::Client::put_object_content) method.
#[derive(TypedBuilder)]
pub struct PutObjectContent {
    #[builder(!default)] // force required
    client: MinioClient,
    #[builder(default, setter(into))]
    extra_headers: Option<Multimap>,
    #[builder(default, setter(into))]
    extra_query_params: Option<Multimap>,
    #[builder(default, setter(into))]
    region: Option<String>,
    #[builder(setter(into))] // force required + accept Into<String>
    bucket: String,
    #[builder(setter(into))] // force required + accept Into<String>
    object: String,
    #[builder(default, setter(into))]
    user_metadata: Option<Multimap>,
    #[builder(default, setter(into))]
    sse: Option<Arc<dyn Sse>>,
    #[builder(default, setter(into))]
    tags: Option<HashMap<String, String>>,
    #[builder(default, setter(into))]
    retention: Option<Retention>,
    #[builder(default = false)]
    legal_hold: bool,
    #[builder(default, setter(into))]
    part_size: Size,
    #[builder(default, setter(into))]
    content_type: Option<String>,

    // source data
    #[builder(!default, setter(into))] // force required + accept Into<String>
    input_content: ObjectContent,

    // Computed.
    // expected_parts: Option<u16>,
    #[builder(default, setter(skip))]
    content_stream: ContentStream,
    #[builder(default, setter(skip))]
    part_count: Option<u16>,
}

/// Builder type for [`PutObjectContent`] that is returned by [`MinioClient::put_object_content`](crate::s3::client::MinioClient::put_object_content).
///
/// This type alias simplifies the complex generic signature generated by the `typed_builder` crate.
pub type PutObjectContentBldr = PutObjectContentBuilder<(
    (MinioClient,),
    (),
    (),
    (),
    (String,),
    (String,),
    (),
    (),
    (),
    (),
    (),
    (),
    (),
    (ObjectContent,),
)>;

impl PutObjectContent {
    pub async fn send(mut self) -> Result<PutObjectContentResponse, Error> {
        check_bucket_name(&self.bucket, true)?;
        check_object_name(&self.object)?;
        check_sse(&self.sse, &self.client)?;

        let input_content = std::mem::take(&mut self.input_content);
        self.content_stream = input_content
            .to_content_stream()
            .await
            .map_err(IoError::from)?;

        // object_size may be Size::Unknown.
        let object_size = self.content_stream.get_size();

        let (part_size, expected_parts) = calc_part_info(object_size, self.part_size)?;
        // Set the chosen part size and part count.
        self.part_size = Size::Known(part_size);
        self.part_count = expected_parts;

        // Read the first part.
        let seg_bytes = self
            .content_stream
            .read_upto(part_size as usize)
            .await
            .map_err(IoError::from)?;

        // In the first part read, if:
        //
        //   - object_size is unknown AND we got less than the part size, OR
        //   - we are expecting only one part to be uploaded,
        //
        // we upload it as a simple put object.
        if (object_size.is_unknown() && (seg_bytes.len() as u64) < part_size)
            || expected_parts == Some(1)
        {
            let size = seg_bytes.len() as u64;

            let resp: PutObjectResponse = PutObject::builder()
                .inner(UploadPart {
                    client: self.client.clone(),
                    extra_headers: self.extra_headers.clone(),
                    extra_query_params: self.extra_query_params.clone(),
                    bucket: self.bucket.clone(),
                    object: self.object.clone(),
                    region: self.region.clone(),
                    user_metadata: self.user_metadata.clone(),
                    sse: self.sse.clone(),
                    tags: self.tags.clone(),
                    retention: self.retention.clone(),
                    legal_hold: self.legal_hold,
                    part_number: None,
                    upload_id: None,
                    data: Arc::new(seg_bytes),
                    content_type: self.content_type.clone(),
                })
                .build()
                .send()
                .await?;

            Ok(PutObjectContentResponse::new(resp, size))
        } else if let Some(expected) = object_size.value()
            && (seg_bytes.len() as u64) < part_size
        {
            // Not enough data!
            let got: u64 = seg_bytes.len() as u64;
            Err(ValidationErr::InsufficientData { expected, got }.into())
        } else {
            let bucket: String = self.bucket.clone();
            let object: String = self.object.clone();

            // Otherwise, we start a multipart upload.
            let create_mpu_resp: CreateMultipartUploadResponse = CreateMultipartUpload::builder()
                .client(self.client.clone())
                .extra_headers(self.extra_headers.clone())
                .extra_query_params(self.extra_query_params.clone())
                .region(self.region.clone())
                .bucket(self.bucket.clone())
                .object(self.object.clone())
                .user_metadata(self.user_metadata.clone())
                .sse(self.sse.clone())
                .tags(self.tags.clone())
                .retention(self.retention.clone())
                .legal_hold(self.legal_hold)
                .content_type(self.content_type.clone())
                .build()
                .send()
                .await?;

            let client = self.client.clone();
            let upload_id: String = create_mpu_resp.upload_id().await?;

            let mpu_res = self
                .send_mpu(part_size, upload_id.clone(), object_size, seg_bytes)
                .await;

            if mpu_res.is_err() {
                // If we failed to complete the multipart upload, we should abort it.
                let _ = AbortMultipartUpload::builder()
                    .client(client)
                    .bucket(bucket)
                    .object(object)
                    .upload_id(upload_id)
                    .build()
                    .send()
                    .await;
            }
            mpu_res
        }
    }

    /// send multi-part-upload
    async fn send_mpu(
        mut self,
        part_size: u64,
        upload_id: String,
        object_size: Size,
        first_part: SegmentedBytes,
    ) -> Result<PutObjectContentResponse, Error> {
        let mut done = false;
        let mut part_number = 0;
        let mut parts: Vec<PartInfo> = if let Some(pc) = self.part_count {
            Vec::with_capacity(pc as usize)
        } else {
            Vec::new()
        };

        let mut first_part = Some(first_part);
        let mut total_read = 0;
        while !done {
            let part_content = {
                if let Some(v) = first_part.take() {
                    v
                } else {
                    self.content_stream
                        .read_upto(part_size as usize)
                        .await
                        .map_err(IoError::from)?
                }
            };
            part_number += 1;
            let buffer_size = part_content.len() as u64;
            total_read += buffer_size;

            assert!(buffer_size <= part_size, "{buffer_size} <= {part_size}",);

            if (buffer_size == 0) && (part_number > 1) {
                // We are done as we uploaded at least 1 part, and we have reached the end of the stream.
                break;
            }

            // Check if we have too many parts to upload.
            if self.part_count.is_none() && (part_number > MAX_MULTIPART_COUNT) {
                return Err(ValidationErr::TooManyParts(part_number as u64).into());
            }

            if let Some(exp) = object_size.value() {
                if exp < total_read {
                    return Err(ValidationErr::TooMuchData(exp).into());
                }
            }

            // Upload the part now.
            let resp: UploadPartResponse = UploadPart {
                client: self.client.clone(),
                extra_headers: self.extra_headers.clone(),
                extra_query_params: self.extra_query_params.clone(),
                bucket: self.bucket.clone(),
                object: self.object.clone(),
                region: self.region.clone(),
                // User metadata is not sent with UploadPart.
                user_metadata: None,
                sse: self.sse.clone(),
                tags: self.tags.clone(),
                retention: self.retention.clone(),
                legal_hold: self.legal_hold,
                part_number: Some(part_number),
                upload_id: Some(upload_id.to_string()),
                data: Arc::new(part_content),
                content_type: self.content_type.clone(),
            }
            .send()
            .await?;

            parts.push(PartInfo {
                number: part_number,
                etag: resp.etag()?,
                size: buffer_size,
            });

            // Finally, check if we are done.
            if buffer_size < part_size {
                done = true;
            }
        }

        // Complete the multipart upload.
        let size = parts.iter().map(|p| p.size).sum();

        if let Some(expected) = object_size.value() {
            if expected != size {
                return Err(ValidationErr::InsufficientData {
                    expected,
                    got: size,
                }
                .into());
            }
        }

        let resp: CompleteMultipartUploadResponse = CompleteMultipartUpload {
            client: self.client,
            extra_headers: self.extra_headers,
            extra_query_params: self.extra_query_params,
            bucket: self.bucket,
            object: self.object,
            region: self.region,
            parts,
            upload_id,
        }
        .send()
        .await?;

        Ok(PutObjectContentResponse::new(resp, size))
    }
}

// endregion: put-object-content

fn into_headers_put_object(
    extra_headers: Option<Multimap>,
    user_metadata: Option<Multimap>,
    sse: Option<Arc<dyn Sse>>,
    tags: Option<HashMap<String, String>>,
    retention: Option<Retention>,
    legal_hold: bool,
    content_type: Option<String>,
) -> Result<Multimap, ValidationErr> {
    let mut map = Multimap::new();

    if let Some(v) = extra_headers {
        map.add_multimap(v);
    }

    if let Some(v) = user_metadata {
        // Validate it.
        for (k, _) in v.iter() {
            if k.is_empty() {
                return Err(ValidationErr::InvalidUserMetadata(
                    "user metadata key cannot be empty".into(),
                ));
            }
            if !k.starts_with("x-amz-meta-") {
                return Err(ValidationErr::InvalidUserMetadata(format!(
                    "user metadata key '{k}' does not start with 'x-amz-meta-'",
                )));
            }
        }
        map.add_multimap(v);
    }

    if let Some(v) = sse {
        map.add_multimap(v.headers());
    }

    if let Some(v) = tags {
        let mut tagging = String::new();
        for (key, value) in v.iter() {
            if !tagging.is_empty() {
                tagging.push('&');
            }
            tagging.push_str(&url_encode(key));
            tagging.push('=');
            tagging.push_str(&url_encode(value));
        }

        if !tagging.is_empty() {
            map.insert(X_AMZ_TAGGING.into(), tagging);
        }
    }

    if let Some(v) = retention {
        map.insert(X_AMZ_OBJECT_LOCK_MODE.into(), v.mode.to_string());
        map.insert(
            X_AMZ_OBJECT_LOCK_RETAIN_UNTIL_DATE.into(),
            to_iso8601utc(v.retain_until_date),
        );
    }

    if legal_hold {
        map.insert(X_AMZ_OBJECT_LOCK_LEGAL_HOLD.into(), "ON".into());
    }

    // Set the Content-Type header if not already set.
    if !map.contains_key(CONTENT_TYPE) {
        map.insert(
            CONTENT_TYPE.into(),
            content_type.unwrap_or("application/octet-stream".into()),
        );
    }

    Ok(map)
}

pub const MIN_PART_SIZE: u64 = 5 * 1024 * 1024; // 5 MiB
pub const MAX_PART_SIZE: u64 = 1024 * MIN_PART_SIZE; // 5 GiB
pub const MAX_OBJECT_SIZE: u64 = 1024 * MAX_PART_SIZE; // 5 TiB
pub const MAX_MULTIPART_COUNT: u16 = 10_000;

/// Returns the size of each part to upload and the total number of parts. The
/// number of parts is `None` when the object size is unknown.
pub fn calc_part_info(
    object_size: Size,
    part_size: Size,
) -> Result<(u64, Option<u16>), ValidationErr> {
    // Validate arguments against limits.
    if let Size::Known(v) = part_size {
        if v < MIN_PART_SIZE {
            return Err(ValidationErr::InvalidMinPartSize(v));
        }

        if v > MAX_PART_SIZE {
            return Err(ValidationErr::InvalidMaxPartSize(v));
        }
    }

    if let Size::Known(v) = object_size
        && v > MAX_OBJECT_SIZE
    {
        return Err(ValidationErr::InvalidObjectSize(v));
    }

    match (object_size, part_size) {
        // If the object size is unknown, the part size must be provided.
        (Size::Unknown, Size::Unknown) => Err(ValidationErr::MissingPartSize),

        // If object size is unknown, and part size is known, the number of
        // parts will be unknown, so return None for that.
        (Size::Unknown, Size::Known(part_size)) => Ok((part_size, None)),

        // If object size is known, and part size is unknown, calculate part
        // size.
        (Size::Known(object_size), Size::Unknown) => {
            // 1. Calculate the minimum part size (i.e., assuming part count is the maximum).
            let mut psize: u64 = (object_size as f64 / MAX_MULTIPART_COUNT as f64).ceil() as u64;

            // 2. Round up to the nearest multiple of MIN_PART_SIZE.
            psize = MIN_PART_SIZE * (psize as f64 / MIN_PART_SIZE as f64).ceil() as u64;

            if psize > object_size {
                psize = object_size;
            }

            let part_count = if psize > 0 {
                (object_size as f64 / psize as f64).ceil() as u16
            } else {
                1
            };

            Ok((psize, Some(part_count)))
        }

        // If both object size and part size are known, validate the resulting
        // part count and return.
        (Size::Known(object_size), Size::Known(part_size)) => {
            let part_count = (object_size as f64 / part_size as f64).ceil() as u16;
            if part_count == 0 || part_count > MAX_MULTIPART_COUNT {
                return Err(ValidationErr::InvalidPartCount {
                    object_size,
                    part_size,
                    part_count: MAX_MULTIPART_COUNT,
                });
            }

            Ok((part_size, Some(part_count)))
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    quickcheck! {
        fn test_calc_part_info(object_size: Size, part_size: Size) -> bool {
            let res = calc_part_info(object_size, part_size);

            // Validate that basic invalid sizes return the expected error.
            if let Size::Known(v) = part_size {
                if v < MIN_PART_SIZE {
                    return match res {
                        Err(ValidationErr::InvalidMinPartSize(v_err)) => v == v_err,
                        _ => false,
                    }
                }
                if v > MAX_PART_SIZE {
                    return match res {
                        Err(ValidationErr::InvalidMaxPartSize(v_err)) => v == v_err,
                        _ => false,
                    }
                }
            }
            if let Size::Known(v) = object_size
                && v > MAX_OBJECT_SIZE {
                    return match res {
                        Err(ValidationErr::InvalidObjectSize(v_err)) => v == v_err,
                        _ => false,
                    }
                }


            // Validate the calculation of part size and part count.
            match (object_size, part_size, res) {
                (Size::Unknown, Size::Unknown, Err(ValidationErr::MissingPartSize)) => true,
                (Size::Unknown, Size::Unknown, _) => false,

                (Size::Unknown, Size::Known(part_size), Ok((psize, None))) => {
                    psize == part_size
                }
                (Size::Unknown, Size::Known(_), _) => false,

                (Size::Known(object_size), Size::Unknown, Ok((psize, Some(part_count)))) => {
                    if object_size < MIN_PART_SIZE  {
                        return psize == object_size && part_count == 1;
                    }
                    if !(MIN_PART_SIZE..=MAX_PART_SIZE).contains(&psize){
                        return false;
                    }
                    if psize > object_size {
                        return false;
                    }
                    (part_count > 0) && (part_count <= MAX_MULTIPART_COUNT)
                }
                (Size::Known(_), Size::Unknown, _) => false,

                (Size::Known(object_size), Size::Known(part_size), res) => {
                    if (part_size > object_size) || ((part_size * (MAX_MULTIPART_COUNT as u64)) < object_size) {
                        return match res {
                            Err(ValidationErr::InvalidPartCount{object_size:v1, part_size:v2, part_count:v3}) => {
                                (v1 == object_size) && (v2 == part_size) && (v3 == MAX_MULTIPART_COUNT)
                            }
                            _ => false,
                        }
                    }
                    match res {
                        Ok((psize, part_count)) => {
                            let expected_part_count = (object_size as f64 / part_size as f64).ceil() as u16;
                            (psize == part_size) && (part_count == Some(expected_part_count))
                        }
                        _ => false,
                    }
                }
            }
        }
    }
}
